[{"categories":["Automação de Tarefas"],"contents":"Scripts em shell são ferramentas poderosas que permitem automatizar diversas tarefas em sistemas Unix e Linux. Ao encapsular uma série de comandos em um único script, é possível otimizar processos, reduzir erros e aumentar a eficiência operacional. Essa linguagem de programação versátil facilita a manipulação de arquivos, a automação de tarefas administrativas e oferece um controle preciso sobre o sistema, tornando-a ideal para diversas aplicações.\nUtilizando o conhecimento adquirido no curso Hands-on Introduction to Linux Commands and Shell Scripting , apliquei em um cenário real o projeto Boutique Manager, que consiste em um sistema de gerenciamento em shell script para pequenas lojas de roupas.\nO sistema proporciona um conjunto integrado de funcionalidades essenciais para a administração de uma loja de roupas, iniciando pelo cadastro de produtos, que permite registrar informações detalhadas por categoria e gerenciar o estoque automaticamente. O módulo de vendas processa transações em tempo real, atualizando o estoque e registrando informações como data, hora e valores. Além disso, um sistema de monitoramento de estoque alerta proativamente sobre níveis baixos de produtos, facilitando a reposição. Relatórios de vendas oferecem análises abrangentes do desempenho do negócio, incluindo totais por categoria e período.\nA segurança e a integridade dos dados são asseguradas por um sistema automatizado de backup, que protege informações críticas diariamente, além de um robusto sistema de logs que registra todas as operações para fins de auditoria. O sistema realiza validações em operações críticas, como a verificação da quantidade disponível em estoque antes das vendas, e usa arquivos temporários para manter a integridade durante atualizações. Todas essas funcionalidades são acessíveis por meio de um menu intuitivo, que organiza as operações de forma lógica, permitindo que usuários com diferentes níveis de experiência operem o sistema com eficiência, resultando em uma gestão mais eficaz e segura da loja.\nObservação: Abra a imagem em uma nova aba do navegador para o zoom necessário.\nO projeto de gerenciamento em shell script utiliza diversas técnicas essenciais, incluindo variáveis de ambiente como LOJA_DIR e DATA, definidas com o comando export para facilitar a configuração do ambiente. A manipulação de dados é otimizada por meio do uso de pipes e filtros, como awk, sort e uniq, permitindo a geração de estatísticas relevantes. Metacaracteres, como * para padrões de arquivos e $(\u0026hellip;) para substituição de comandos, também são empregados para aumentar a flexibilidade do script. O redirecionamento de I/O é utilizado para registrar logs e criar novos arquivos, assegurando uma gestão eficiente dos dados.\nA modularização do código por meio de funções melhora a legibilidade e a manutenção, enquanto a passagem de parâmetros permite uma maior reutilização. Estruturas condicionais, como if/then/else e case, são aplicadas para gerenciar o menu do sistema, complementadas por loops while, que facilitam a interação com o usuário e a iteração sobre arrays, como o de categorias. O agendamento de tarefas é gerenciado pelo cron, garantindo a realização de backups automáticos e verificações semanais do estoque, o que contribui para a robustez e a confiabilidade do sistema. A segurança dos dados é assegurada através de operações atômicas usando arquivos temporários durante atualizações, enquanto o registro de todas as operações é mantido por meio de logs com data e hora, utilizando o comando date.\nOs benefícios da automação por meio de scripts são vastos. Ao automatizar tarefas repetitivas, é possível economizar tempo, reduzir o risco de erros humanos e garantir a consistência dos processos. Além disso, scripts podem ser utilizados para monitorar sistemas, gerar relatórios e realizar backups, proporcionando uma maior segurança e confiabilidade. Em um mundo cada vez mais digital, a automação por meio de scripts se torna um diferencial competitivo para empresas que buscam otimizar seus processos e alcançar a excelência operacional.\nPara mais detalhes, implementar este projeto ou fornecer sugestões e melhorias, acesse o link do repositório abaixo.\nRepositório do projeto https://github.com/diogo-dantas/boutique-manager\nDesigned by gstudioimagen / Freepik\n","date":"October 31, 2024","hero":"/posts/task-automation/shell-script/boutique-manager/images/post2.jpg","permalink":"https://diogo-dantas.github.io/pt-br/posts/task-automation/shell-script/boutique-manager/","summary":"\u003cp\u003eScripts em shell são ferramentas poderosas que permitem automatizar diversas tarefas em sistemas Unix e Linux. Ao encapsular uma série de comandos em um único script, é possível otimizar processos, reduzir erros e aumentar a eficiência operacional. Essa linguagem de programação versátil facilita a manipulação de arquivos, a automação de tarefas administrativas e oferece um controle preciso sobre o sistema, tornando-a ideal para diversas aplicações.\u003c/p\u003e\n\u003cp\u003eUtilizando o conhecimento adquirido no curso \u003ca href=\"https://www.coursera.org/account/accomplishments/verify/30JGE2RZY8T4\" title=\"Visite o certificado do curso\" target=\"_blank\" rel=\"noopener\"\u003eHands-on Introduction to Linux Commands and Shell Scripting\u003c/a\u003e , apliquei em um cenário real o projeto Boutique Manager, que consiste em um sistema de gerenciamento em shell script para pequenas lojas de roupas.\u003c/p\u003e","tags":["Cron","Shell Script","Bash (Unix Shell)"],"title":"Gerenciamento Inteligente: Integrando Shell script e automatizando tarefas"},{"categories":["Engenharia de Dados"],"contents":"No ambiente dinâmico de trabalho atual, a integração e a análise de dados provenientes de diversas fontes são fundamentais para a tomada de decisões informadas. Em muitos setores, como o financeiro, logístico ou de marketing, é comum receber arquivos de dados em diferentes formatos, como CSV, XML e JSON. Esses arquivos podem conter informações valiosas, mas sua dispersão e diversidade de formatos tornam o processamento e a análise um desafio significativo.\nNeste cenário, um dos desafios enfrentados é a necessidade de consolidar informações provenientes de múltiplos arquivos em um único formato que possa ser facilmente importado para um banco de dados, por exemplo. A tarefa torna-se ainda mais crítica quando se considera a necessidade de manter a integridade e a consistência dos dados durante esse processo de compilação.\nPara ilustrar uma solução simples e eficaz para esse desafio, utilizei como exemplo arquivos contendo informações de nome, altura e peso, disponíveis em um diretório central específico para esse propósito. Os dados estão armazenados em diferentes formatos: CSV, JSON e XML.\nETL é um processo fundamental em gerenciamento de dados e integração de sistemas. Por meio deste processo utilizando a linguagem python e as bibliotecas: glob, pandas, datetime e ElementTree serão extraídas as informações dos arquivos, transformando o peso de polegadas para kg e a altura de libra para metro mediante regra do negócio estipulada. Os dados compilados serão devolvidos em um arquivo csv intitulado transformed_data.csv\u0026quot;. Outro arquivo de saída fundamental para armazenar todas as ações realizadas durante o processo de ETL, será o arquivo \u0026ldquo;log_file.txt\u0026rdquo;.\nA importância de um arquivo de log em um processo ETL reside em sua capacidade de fornecer um rastro completo de todas as atividades realizadas. Ao registrar detalhadamente cada etapa, o log permite que as equipes monitorem a execução em tempo real, detectem e resolvam problemas rapidamente, otimizem o desempenho do processo, cumpram com requisitos regulatórios e documentem todas as ações para futuras referências. Além disso, a análise regular dos logs permite identificar oportunidades de melhoria contínua, garantindo que o processo ETL seja sempre eficiente e eficaz.\nO vídeo abaixo apresenta uma síntese da solução proposta para o projeto.\nPodemos imaginar outros cenários, como por exemplo, em que uma empresa recebe relatórios diários de vendas, estoque e feedback de clientes em diferentes formatos. Para otimizar a análise e a geração de relatórios, é essencial compilar todas essas informações em um único arquivo CSV.\nEm resumo, a compilação de dados é um processo crucial para transformar informações dispersas em conhecimento útil. Ao automatizar e otimizar esse processo, as empresas podem extrair o máximo valor de seus dados, impulsionando o crescimento e a competitividade.\nRepositório do projeto https://github.com/diogo-dantas/ETL-simplificado-CSV-JSON-e-XML-\nDesigned by gstudioimagen / Freepik\n","date":"September 20, 2024","hero":"/posts/etl/python/etl-simplificado/images/post1.jpg","permalink":"https://diogo-dantas.github.io/pt-br/posts/etl/python/etl-simplificado/","summary":"\u003cp\u003eNo ambiente dinâmico de trabalho atual, a integração e a análise de dados provenientes de diversas fontes são fundamentais para a tomada de decisões informadas. Em muitos setores, como o financeiro, logístico ou de marketing, é comum receber arquivos de dados em diferentes formatos, como CSV, XML e JSON. Esses arquivos podem conter informações valiosas, mas sua dispersão e diversidade de formatos tornam o processamento e a análise um desafio significativo.\u003c/p\u003e","tags":["ETL","Python"],"title":"ETL simplificado: dados unificados"}]